# -*- coding: utf-8 -*-
# pylint: disable=C0103,C0301
# flake8: noqa: E501
"""
Pipefy dumping tasks
"""
import datetime
import os
import time
from typing import List
from datetime import timedelta

import requests
from prefeitura_rio.pipelines_utils.logging import log

from pipelines.datalake.extract_load.seguir_em_frente_pipefy.constants import (
    constants as pipefy_constants,
)
from pipelines.datalake.utils.data_transformations import (
    conform_header_to_datalake,
    convert_to_parquet,
)
from pipelines.utils.credential_injector import authenticated_task as task
from pipelines.utils.tasks import get_secret_key


@task
def pipefy_generate_access_token(environment: str = "prod") -> str:
    """
    Generates an access token for the Pipefy API.

    Args:
        environment (str, optional): The environment to use for retrieving the client ID and client secret. Defaults to "prod".

    Returns:
        str: The access token generated by the Pipefy API.
    """

    client_id = get_secret_key.run(
        secret_path=pipefy_constants.INFISICAL_PATH.value,
        secret_name=pipefy_constants.INFISICAL_PIPEFY_CLIENT_ID.value,
        environment=environment,
    )
    client_secret = get_secret_key.run(
        secret_path=pipefy_constants.INFISICAL_PATH.value,
        secret_name=pipefy_constants.INFISICAL_PIPEFY_CLIENT_SECRET.value,
        environment=environment,
    )

    url = "https://app.pipefy.com/oauth/token"

    payload = {
        "grant_type": "client_credentials",
        "client_id": client_id,
        "client_secret": client_secret,
    }
    headers = {"accept": "application/json", "content-type": "application/json"}

    response = requests.post(url, json=payload, headers=headers, timeout=30)

    if response.status_code != 200:
        log(f"Error generating access token: {response.text}", level="error")
        raise ConnectionError(f"Error generating access token: {response.text}")

    log("Access token generated successfully")
    return response.json()["access_token"]


@task(max_retries=2, retry_delay=timedelta(minutes=1))
def download_from_pipefy(
    endpoint: str, destination_folder: str, environment: str = "dev"
) -> List[str]:
    """
    Downloads a report from Pipefy and saves it to the specified destination folder.

    Args:
        endpoint (str): The endpoint of the report to download.
        destination_folder (str): The folder where the downloaded file will be saved.
        environment (str, optional): The environment to use for generating the access token. Defaults to "dev".

    Returns:
        List[str]: A list containing the file path of the downloaded file.

    Raises:
        ConnectionError: If there is an error downloading the file.

    """
    access_token = pipefy_generate_access_token.run(environment=environment)

    url = "https://api.pipefy.com/graphql"
    headers = {
        "accept": "application/json",
        "content-type": "application/json",
        "Authorization": f"Bearer {access_token}",
    }

    # Request report exportation
    pipe_id = pipefy_constants.ENPOINT.value[endpoint]["pipe_id"]
    report_id = pipefy_constants.ENPOINT.value[endpoint]["report_id"]

    body = (
        "mutation { \n exportPipeReport(input: {"
        + f"pipeId: {pipe_id}, pipeReportId: {report_id}"
        + "}) { \n pipeReportExport { \n id \n } \n } \n }"
    )  # noqa

    payload = {"query": body}
    response = requests.post(url, json=payload, headers=headers, timeout=30)
    export_id = response.json()["data"]["exportPipeReport"]["pipeReportExport"]["id"]

    log(f"Report URL requested with ID: {export_id}")

    # Request report exportation's url
    body = (
        "{ \n pipeReportExport(id: "
        + export_id
        + " ) { \n fileURL \n state \n startedAt \n requestedBy { \n id \n } \n } \n }"
    )  # noqa
    payload = {"query": body}
    response = requests.post(url, json=payload, headers=headers, timeout=30)
    export_url = response.json()["data"]["pipeReportExport"]["fileURL"]

    log(f"Report URL: {export_url}")

    # Download the file to destination folder
    time.sleep(10)
    current_date = datetime.date.today().strftime("%Y-%m-%d")
    file_path = os.path.join(destination_folder, f"{endpoint}_{current_date}.xlsx")
    response = requests.get(export_url, timeout=240)

    if response.status_code != 200:
        log(f"Error downloading file: {response.text}", level="error")
        raise ConnectionError(f"Error downloading file: {response.text}")
    with open(file_path, "wb") as file:
        file.write(response.content)
    log(f"Report downloaded to: {file_path}")
    return [file_path]


@task
def transform_data(files_path: List[str]) -> List[str]:
    """
    Transforms the data files in the given list of file paths.

    Args:
        files_path (List[str]): A list of file paths to be transformed.

    Returns:
        List[str]: A list of transformed file paths.

    """
    transformed_files = []

    for file in files_path:

        log(f"Transforming file: {os.path.basename(file)}")

        parquet_file_path = convert_to_parquet(file_path=file, file_type="xlsx")

        parquet_file_path = conform_header_to_datalake(
            file_path=parquet_file_path,
            file_type="parquet",
        )

        transformed_files.append(parquet_file_path)

    return transformed_files
