{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetctive\n",
    "\n",
    "This noteobook updates CSV files in a Google Cloud Storage bucket by adding a new column to all CSV files missing this information.\n",
    "\n",
    "This function performs the following steps:\n",
    "1. Backs up all CSV files before making any changes\n",
    "2. Downloads each CSV file to a temporary folder, updates each CSV file by adding a new column and reordering the columns, uploads the updated CSV file back to the bucket, replacing the old one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.oauth2.service_account import Credentials\n",
    "from google.cloud import storage\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE CLOUD\n",
    "key_file_path = \"/Users/.credentials/google.json\"\n",
    "bucket_name = \"bucket-name\"\n",
    "\n",
    "# Specify the prefixes (folders) you want to scan\n",
    "prefixes = [\n",
    "    \"staging/brutos_prontuario_vitai/estoque_posicao/\",\n",
    "]\n",
    "\n",
    "# LOCAL\n",
    "backup_folder = \"/Users/tmp/\"\n",
    "tmp_folder = \"/Users/projects/pipelines_rj_sms/data/raw/\"\n",
    "\n",
    "# PAYLOAD\n",
    "new_column = \"ultimaAtualizacao\"\n",
    "columns_order = [\n",
    "    \"id\",\n",
    "    \"produtoId\",\n",
    "    \"estabelecimentoId\",\n",
    "    \"cnes\",\n",
    "    \"sigla\",\n",
    "    \"produtoCodigo\",\n",
    "    \"descricao\",\n",
    "    \"grupo\",\n",
    "    \"subGrupo\",\n",
    "    \"categoria\",\n",
    "    \"apresentacao\",\n",
    "    \"lote\",\n",
    "    \"secao\",\n",
    "    \"dataVencimento\",\n",
    "    \"controlado\",\n",
    "    \"saldo\",\n",
    "    \"valorMedio\",\n",
    "    \"dataHora\",\n",
    "    \"ultimaAtualizacao\",\n",
    "    \"_data_carga\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Backup Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = Credentials.from_service_account_file(key_file_path)\n",
    "client = storage.Client(credentials=credentials)\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "# Calculate the total number of files\n",
    "total_files = 0\n",
    "\n",
    "for prefix in prefixes:\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith(\".csv\"):\n",
    "            total_files += 1\n",
    "\n",
    "print(f\"Total files: {total_files}\")\n",
    "\n",
    "\n",
    "# Start backing up the files\n",
    "for prefix in prefixes:\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "    for blob in tqdm.notebook.tqdm(blobs, total=total_files):\n",
    "        if blob.name.endswith(\".csv\"):\n",
    "            blob.download_to_filename(f'{backup_folder}{blob.name.split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transform Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = f\"{tmp_folder}temp.csv\"\n",
    "\n",
    "\n",
    "for prefix in prefixes:\n",
    "\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "    for blob in tqdm.notebook.tqdm(blobs, total=total_files):\n",
    "\n",
    "        if blob.name.endswith(\".csv\"):\n",
    "            blob.download_to_filename(tmp_path)\n",
    "\n",
    "            df = pd.read_csv(\n",
    "                tmp_path,\n",
    "                sep=\";\",\n",
    "                dtype=str,\n",
    "                keep_default_na=False,\n",
    "                encoding=\"utf-8\",\n",
    "            )\n",
    "\n",
    "            if new_column not in df.columns:\n",
    "                df[new_column] = \"\"\n",
    "\n",
    "            df = df[columns_order]\n",
    "\n",
    "            # Save the updated DataFrame back to a CSV file\n",
    "            df.to_csv(tmp_path, index=False, sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "            # Upload the updated CSV file, replacing the old one\n",
    "            blob.upload_from_filename(tmp_path)\n",
    "\n",
    "print(\"All CSV files have been updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caixa_de_areia-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
