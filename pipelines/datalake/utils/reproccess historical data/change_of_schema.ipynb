{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "This notebook updates CSV files in a Google Cloud Storage bucket by adding new columns to all CSV files missing this information.\n",
    "\n",
    "This function performs the following steps:\n",
    "1. Backs up all CSV files before making any changes\n",
    "2. Updates each CSV file by adding a new column and reordering the columns, uploads the updated CSV file back to the bucket, replacing the old one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from google.oauth2.service_account import Credentials\n",
    "from google.cloud import storage\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Backup Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE CLOUD\n",
    "key_file_path = \"/Users/.credentials/rj-sms.json\"\n",
    "bucket_name = \"rj-sms\"\n",
    "\n",
    "# Specify the prefixes (folders) you want to scan\n",
    "prefixes = [\n",
    "    \"staging/brutos_prontuario_vitacare/estoque_movimento/\",\n",
    "]\n",
    "\n",
    "# LOCAL\n",
    "backup_folder = \"/Users/tmp\"\n",
    "tmp_folder = \"/Users/projects/pipelines_rj_sms/data/raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 32183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0635f4c0b204a4782e880a2054da771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "credentials = Credentials.from_service_account_file(key_file_path)\n",
    "client = storage.Client(credentials=credentials)\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "# Calculate the total number of files\n",
    "total_files = 0\n",
    "\n",
    "for prefix in prefixes:\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith(\".csv\"):\n",
    "            total_files += 1\n",
    "\n",
    "print(f\"Total files: {total_files}\")\n",
    "\n",
    "\n",
    "# Start backing up the files\n",
    "for prefix in prefixes:\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "    for blob in tqdm(blobs, total=total_files):\n",
    "        if blob.name.endswith(\".csv\"):\n",
    "            file = blob.name.split(\"/\")[-1]\n",
    "            if file not in os.listdir(backup_folder):\n",
    "                blob.download_to_filename(f\"{backup_folder}/{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Update & Upload Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAYLOAD\n",
    "new_columns = [\"cpfProfPrescritor\", \"codWms\", \"armazemOrigem\", \"armazemDestino\"]\n",
    "columns_order = [\n",
    "    \"ap\",\n",
    "    \"cnesUnidade\",\n",
    "    \"nomeUnidade\",\n",
    "    \"desigMedicamento\",\n",
    "    \"atc\",\n",
    "    \"code\",\n",
    "    \"lote\",\n",
    "    \"dtaMovimento\",\n",
    "    \"tipoMovimento\",\n",
    "    \"motivoCorrecao\",\n",
    "    \"justificativa\",\n",
    "    \"cpfProfPrescritor\",\n",
    "    \"cnsProfPrescritor\",\n",
    "    \"cpfPatient\",\n",
    "    \"cnsPatient\",\n",
    "    \"qtd\",\n",
    "    \"codWms\",\n",
    "    \"armazemOrigem\",\n",
    "    \"armazemDestino\",\n",
    "    \"id\",\n",
    "    \"_data_carga\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Update & Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74dfa53b1a1491da4ce0501e388e60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file estoque_movimento_ap33_cnes6761704_2024-03-23.csv: No columns to parse from file\n",
      "Error processing file estoque_movimento_ap33_cnes2269759_2024-05-15.csv: No columns to parse from file\n",
      "Error processing file estoque_movimento_ap32_cnes6919626_2024-06-26.csv: No columns to parse from file\n",
      "All CSV files have been updated.\n"
     ]
    }
   ],
   "source": [
    "tmp_path = f\"{backup_folder}/_temp.csv\"\n",
    "\n",
    "for prefix in prefixes:\n",
    "\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "    for blob in tqdm(blobs, total=total_files):\n",
    "\n",
    "        if blob.name.endswith(\".csv\"):\n",
    "\n",
    "            if blob.updated < datetime.datetime(\n",
    "                2024, 7, 19, 6, 30, 0, 0, tzinfo=datetime.timezone.utc\n",
    "            ):\n",
    "\n",
    "                file = blob.name.split(\"/\")[-1]\n",
    "\n",
    "                try:\n",
    "                    df = pd.read_csv(\n",
    "                        f\"{backup_folder}/{file}\",\n",
    "                        sep=\";\",\n",
    "                        dtype=str,\n",
    "                        keep_default_na=False,\n",
    "                        encoding=\"utf-8\",\n",
    "                    )\n",
    "\n",
    "                    for new_column in new_columns:\n",
    "                        if new_column not in df.columns:\n",
    "                            df[new_column] = \"\"\n",
    "\n",
    "                    df = df[columns_order]\n",
    "                    df.to_csv(tmp_path, index=False, sep=\";\", encoding=\"utf-8\")\n",
    "                    blob.upload_from_filename(tmp_path)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "print(\"All CSV files have been updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caixa_de_areia-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
